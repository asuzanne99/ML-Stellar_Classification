{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf248d5a",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484f0821",
   "metadata": {},
   "source": [
    "### Part 0: Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e83f0988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/opt/anaconda3/lib/python3.9/site-packages', '/Users/nalic/Documents/GitHub/ML-Stellar_Classification', '/Users/nalic/anaconda3/lib/python310.zip', '/Users/nalic/anaconda3/lib/python3.10', '/Users/nalic/anaconda3/lib/python3.10/lib-dynload', '', '/Users/nalic/anaconda3/lib/python3.10/site-packages', '/Users/nalic/anaconda3/lib/python3.10/site-packages/PyQt5_sip-12.11.0-py3.10-macosx-10.9-x86_64.egg', '/Users/nalic/anaconda3/lib/python3.10/site-packages/aeosa', '/Users/nalic/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg', '/Users/nalic/anaconda3/lib/python3.10/site-packages/pycurl-7.45.1-py3.10-macosx-10.9-x86_64.egg']\n"
     ]
    }
   ],
   "source": [
    "#having issues with numpy (and jupyter notebook) so have to use the following 3 lines for now...\n",
    "import sys\n",
    "sys.path.insert(0,'/opt/anaconda3/lib/python3.9/site-packages')\n",
    "print(sys.path)\n",
    "\n",
    "# edit\n",
    "#import statements\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c57532b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obj_ID</th>\n",
       "      <th>alpha</th>\n",
       "      <th>delta</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>run_ID</th>\n",
       "      <th>rerun_ID</th>\n",
       "      <th>cam_col</th>\n",
       "      <th>field_ID</th>\n",
       "      <th>spec_obj_ID</th>\n",
       "      <th>class</th>\n",
       "      <th>redshift</th>\n",
       "      <th>plate</th>\n",
       "      <th>MJD</th>\n",
       "      <th>fiber_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.237661e+18</td>\n",
       "      <td>135.689107</td>\n",
       "      <td>32.494632</td>\n",
       "      <td>23.87882</td>\n",
       "      <td>22.27530</td>\n",
       "      <td>20.39501</td>\n",
       "      <td>19.16573</td>\n",
       "      <td>18.79371</td>\n",
       "      <td>3606</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>6.543777e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.634794</td>\n",
       "      <td>5812</td>\n",
       "      <td>56354</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.237665e+18</td>\n",
       "      <td>144.826101</td>\n",
       "      <td>31.274185</td>\n",
       "      <td>24.77759</td>\n",
       "      <td>22.83188</td>\n",
       "      <td>22.58444</td>\n",
       "      <td>21.16812</td>\n",
       "      <td>21.61427</td>\n",
       "      <td>4518</td>\n",
       "      <td>301</td>\n",
       "      <td>5</td>\n",
       "      <td>119</td>\n",
       "      <td>1.176014e+19</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.779136</td>\n",
       "      <td>10445</td>\n",
       "      <td>58158</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.237661e+18</td>\n",
       "      <td>142.188790</td>\n",
       "      <td>35.582444</td>\n",
       "      <td>25.26307</td>\n",
       "      <td>22.66389</td>\n",
       "      <td>20.60976</td>\n",
       "      <td>19.34857</td>\n",
       "      <td>18.94827</td>\n",
       "      <td>3606</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>5.152200e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.644195</td>\n",
       "      <td>4576</td>\n",
       "      <td>55592</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.237663e+18</td>\n",
       "      <td>338.741038</td>\n",
       "      <td>-0.402828</td>\n",
       "      <td>22.13682</td>\n",
       "      <td>23.77656</td>\n",
       "      <td>21.61162</td>\n",
       "      <td>20.50454</td>\n",
       "      <td>19.25010</td>\n",
       "      <td>4192</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>214</td>\n",
       "      <td>1.030107e+19</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.932346</td>\n",
       "      <td>9149</td>\n",
       "      <td>58039</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.237680e+18</td>\n",
       "      <td>345.282593</td>\n",
       "      <td>21.183866</td>\n",
       "      <td>19.43718</td>\n",
       "      <td>17.58028</td>\n",
       "      <td>16.49747</td>\n",
       "      <td>15.97711</td>\n",
       "      <td>15.54461</td>\n",
       "      <td>8102</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>137</td>\n",
       "      <td>6.891865e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.116123</td>\n",
       "      <td>6121</td>\n",
       "      <td>56187</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.237680e+18</td>\n",
       "      <td>340.995121</td>\n",
       "      <td>20.589476</td>\n",
       "      <td>23.48827</td>\n",
       "      <td>23.33776</td>\n",
       "      <td>21.32195</td>\n",
       "      <td>20.25615</td>\n",
       "      <td>19.54544</td>\n",
       "      <td>8102</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>5.658977e+18</td>\n",
       "      <td>QSO</td>\n",
       "      <td>1.424659</td>\n",
       "      <td>5026</td>\n",
       "      <td>55855</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.237679e+18</td>\n",
       "      <td>23.234926</td>\n",
       "      <td>11.418188</td>\n",
       "      <td>21.46973</td>\n",
       "      <td>21.17624</td>\n",
       "      <td>20.92829</td>\n",
       "      <td>20.60826</td>\n",
       "      <td>20.42573</td>\n",
       "      <td>7773</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>462</td>\n",
       "      <td>1.246262e+19</td>\n",
       "      <td>QSO</td>\n",
       "      <td>0.586455</td>\n",
       "      <td>11069</td>\n",
       "      <td>58456</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.237679e+18</td>\n",
       "      <td>5.433176</td>\n",
       "      <td>12.065186</td>\n",
       "      <td>22.24979</td>\n",
       "      <td>22.02172</td>\n",
       "      <td>20.34126</td>\n",
       "      <td>19.48794</td>\n",
       "      <td>18.84999</td>\n",
       "      <td>7773</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>346</td>\n",
       "      <td>6.961443e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.477009</td>\n",
       "      <td>6183</td>\n",
       "      <td>56210</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.237661e+18</td>\n",
       "      <td>200.290475</td>\n",
       "      <td>47.199402</td>\n",
       "      <td>24.40286</td>\n",
       "      <td>22.35669</td>\n",
       "      <td>20.61032</td>\n",
       "      <td>19.46490</td>\n",
       "      <td>18.95852</td>\n",
       "      <td>3716</td>\n",
       "      <td>301</td>\n",
       "      <td>5</td>\n",
       "      <td>108</td>\n",
       "      <td>7.459285e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.660012</td>\n",
       "      <td>6625</td>\n",
       "      <td>56386</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.237671e+18</td>\n",
       "      <td>39.149691</td>\n",
       "      <td>28.102842</td>\n",
       "      <td>21.74669</td>\n",
       "      <td>20.03493</td>\n",
       "      <td>19.17553</td>\n",
       "      <td>18.81823</td>\n",
       "      <td>18.65422</td>\n",
       "      <td>5934</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>122</td>\n",
       "      <td>2.751763e+18</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>2444</td>\n",
       "      <td>54082</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.237680e+18</td>\n",
       "      <td>328.092076</td>\n",
       "      <td>18.220310</td>\n",
       "      <td>25.77163</td>\n",
       "      <td>22.52042</td>\n",
       "      <td>20.63884</td>\n",
       "      <td>19.78071</td>\n",
       "      <td>19.05765</td>\n",
       "      <td>8102</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>5.652162e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.459596</td>\n",
       "      <td>5020</td>\n",
       "      <td>55852</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.237662e+18</td>\n",
       "      <td>243.986637</td>\n",
       "      <td>25.738280</td>\n",
       "      <td>23.76761</td>\n",
       "      <td>23.79969</td>\n",
       "      <td>20.98318</td>\n",
       "      <td>19.80745</td>\n",
       "      <td>19.45579</td>\n",
       "      <td>3927</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>5.322364e+18</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.591409</td>\n",
       "      <td>4727</td>\n",
       "      <td>55693</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          obj_ID       alpha      delta         u         g         r  \\\n",
       "0   1.237661e+18  135.689107  32.494632  23.87882  22.27530  20.39501   \n",
       "1   1.237665e+18  144.826101  31.274185  24.77759  22.83188  22.58444   \n",
       "2   1.237661e+18  142.188790  35.582444  25.26307  22.66389  20.60976   \n",
       "3   1.237663e+18  338.741038  -0.402828  22.13682  23.77656  21.61162   \n",
       "4   1.237680e+18  345.282593  21.183866  19.43718  17.58028  16.49747   \n",
       "5   1.237680e+18  340.995121  20.589476  23.48827  23.33776  21.32195   \n",
       "6   1.237679e+18   23.234926  11.418188  21.46973  21.17624  20.92829   \n",
       "7   1.237679e+18    5.433176  12.065186  22.24979  22.02172  20.34126   \n",
       "8   1.237661e+18  200.290475  47.199402  24.40286  22.35669  20.61032   \n",
       "9   1.237671e+18   39.149691  28.102842  21.74669  20.03493  19.17553   \n",
       "10  1.237680e+18  328.092076  18.220310  25.77163  22.52042  20.63884   \n",
       "11  1.237662e+18  243.986637  25.738280  23.76761  23.79969  20.98318   \n",
       "\n",
       "           i         z  run_ID  rerun_ID  cam_col  field_ID   spec_obj_ID  \\\n",
       "0   19.16573  18.79371    3606       301        2        79  6.543777e+18   \n",
       "1   21.16812  21.61427    4518       301        5       119  1.176014e+19   \n",
       "2   19.34857  18.94827    3606       301        2       120  5.152200e+18   \n",
       "3   20.50454  19.25010    4192       301        3       214  1.030107e+19   \n",
       "4   15.97711  15.54461    8102       301        3       137  6.891865e+18   \n",
       "5   20.25615  19.54544    8102       301        3       110  5.658977e+18   \n",
       "6   20.60826  20.42573    7773       301        2       462  1.246262e+19   \n",
       "7   19.48794  18.84999    7773       301        2       346  6.961443e+18   \n",
       "8   19.46490  18.95852    3716       301        5       108  7.459285e+18   \n",
       "9   18.81823  18.65422    5934       301        4       122  2.751763e+18   \n",
       "10  19.78071  19.05765    8102       301        3        27  5.652162e+18   \n",
       "11  19.80745  19.45579    3927       301        4       112  5.322364e+18   \n",
       "\n",
       "     class  redshift  plate    MJD  fiber_ID  \n",
       "0   GALAXY  0.634794   5812  56354       171  \n",
       "1   GALAXY  0.779136  10445  58158       427  \n",
       "2   GALAXY  0.644195   4576  55592       299  \n",
       "3   GALAXY  0.932346   9149  58039       775  \n",
       "4   GALAXY  0.116123   6121  56187       842  \n",
       "5      QSO  1.424659   5026  55855       741  \n",
       "6      QSO  0.586455  11069  58456       113  \n",
       "7   GALAXY  0.477009   6183  56210        15  \n",
       "8   GALAXY  0.660012   6625  56386       719  \n",
       "9     STAR -0.000008   2444  54082       232  \n",
       "10  GALAXY  0.459596   5020  55852       525  \n",
       "11  GALAXY  0.591409   4727  55693       855  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in the dataset\n",
    "path = \"star_classification.csv\"\n",
    "raw_data = pd.read_csv(path)\n",
    "\n",
    "#raw_data\n",
    "\n",
    "raw_data[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3b497f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obj_ID</th>\n",
       "      <th>alpha</th>\n",
       "      <th>delta</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>run_ID</th>\n",
       "      <th>rerun_ID</th>\n",
       "      <th>cam_col</th>\n",
       "      <th>field_ID</th>\n",
       "      <th>spec_obj_ID</th>\n",
       "      <th>class</th>\n",
       "      <th>redshift</th>\n",
       "      <th>plate</th>\n",
       "      <th>MJD</th>\n",
       "      <th>fiber_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.237661e+18</td>\n",
       "      <td>135.689107</td>\n",
       "      <td>32.494632</td>\n",
       "      <td>23.87882</td>\n",
       "      <td>22.27530</td>\n",
       "      <td>20.39501</td>\n",
       "      <td>19.16573</td>\n",
       "      <td>18.79371</td>\n",
       "      <td>3606</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>6.543777e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634794</td>\n",
       "      <td>5812</td>\n",
       "      <td>56354</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.237665e+18</td>\n",
       "      <td>144.826101</td>\n",
       "      <td>31.274185</td>\n",
       "      <td>24.77759</td>\n",
       "      <td>22.83188</td>\n",
       "      <td>22.58444</td>\n",
       "      <td>21.16812</td>\n",
       "      <td>21.61427</td>\n",
       "      <td>4518</td>\n",
       "      <td>301</td>\n",
       "      <td>5</td>\n",
       "      <td>119</td>\n",
       "      <td>1.176014e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.779136</td>\n",
       "      <td>10445</td>\n",
       "      <td>58158</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.237661e+18</td>\n",
       "      <td>142.188790</td>\n",
       "      <td>35.582444</td>\n",
       "      <td>25.26307</td>\n",
       "      <td>22.66389</td>\n",
       "      <td>20.60976</td>\n",
       "      <td>19.34857</td>\n",
       "      <td>18.94827</td>\n",
       "      <td>3606</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>5.152200e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.644195</td>\n",
       "      <td>4576</td>\n",
       "      <td>55592</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.237663e+18</td>\n",
       "      <td>338.741038</td>\n",
       "      <td>-0.402828</td>\n",
       "      <td>22.13682</td>\n",
       "      <td>23.77656</td>\n",
       "      <td>21.61162</td>\n",
       "      <td>20.50454</td>\n",
       "      <td>19.25010</td>\n",
       "      <td>4192</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>214</td>\n",
       "      <td>1.030107e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.932346</td>\n",
       "      <td>9149</td>\n",
       "      <td>58039</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.237680e+18</td>\n",
       "      <td>345.282593</td>\n",
       "      <td>21.183866</td>\n",
       "      <td>19.43718</td>\n",
       "      <td>17.58028</td>\n",
       "      <td>16.49747</td>\n",
       "      <td>15.97711</td>\n",
       "      <td>15.54461</td>\n",
       "      <td>8102</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>137</td>\n",
       "      <td>6.891865e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.116123</td>\n",
       "      <td>6121</td>\n",
       "      <td>56187</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.237680e+18</td>\n",
       "      <td>340.995121</td>\n",
       "      <td>20.589476</td>\n",
       "      <td>23.48827</td>\n",
       "      <td>23.33776</td>\n",
       "      <td>21.32195</td>\n",
       "      <td>20.25615</td>\n",
       "      <td>19.54544</td>\n",
       "      <td>8102</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>5.658977e+18</td>\n",
       "      <td>1</td>\n",
       "      <td>1.424659</td>\n",
       "      <td>5026</td>\n",
       "      <td>55855</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.237679e+18</td>\n",
       "      <td>23.234926</td>\n",
       "      <td>11.418188</td>\n",
       "      <td>21.46973</td>\n",
       "      <td>21.17624</td>\n",
       "      <td>20.92829</td>\n",
       "      <td>20.60826</td>\n",
       "      <td>20.42573</td>\n",
       "      <td>7773</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>462</td>\n",
       "      <td>1.246262e+19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.586455</td>\n",
       "      <td>11069</td>\n",
       "      <td>58456</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.237679e+18</td>\n",
       "      <td>5.433176</td>\n",
       "      <td>12.065186</td>\n",
       "      <td>22.24979</td>\n",
       "      <td>22.02172</td>\n",
       "      <td>20.34126</td>\n",
       "      <td>19.48794</td>\n",
       "      <td>18.84999</td>\n",
       "      <td>7773</td>\n",
       "      <td>301</td>\n",
       "      <td>2</td>\n",
       "      <td>346</td>\n",
       "      <td>6.961443e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.477009</td>\n",
       "      <td>6183</td>\n",
       "      <td>56210</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.237661e+18</td>\n",
       "      <td>200.290475</td>\n",
       "      <td>47.199402</td>\n",
       "      <td>24.40286</td>\n",
       "      <td>22.35669</td>\n",
       "      <td>20.61032</td>\n",
       "      <td>19.46490</td>\n",
       "      <td>18.95852</td>\n",
       "      <td>3716</td>\n",
       "      <td>301</td>\n",
       "      <td>5</td>\n",
       "      <td>108</td>\n",
       "      <td>7.459285e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.660012</td>\n",
       "      <td>6625</td>\n",
       "      <td>56386</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.237671e+18</td>\n",
       "      <td>39.149691</td>\n",
       "      <td>28.102842</td>\n",
       "      <td>21.74669</td>\n",
       "      <td>20.03493</td>\n",
       "      <td>19.17553</td>\n",
       "      <td>18.81823</td>\n",
       "      <td>18.65422</td>\n",
       "      <td>5934</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>122</td>\n",
       "      <td>2.751763e+18</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>2444</td>\n",
       "      <td>54082</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.237680e+18</td>\n",
       "      <td>328.092076</td>\n",
       "      <td>18.220310</td>\n",
       "      <td>25.77163</td>\n",
       "      <td>22.52042</td>\n",
       "      <td>20.63884</td>\n",
       "      <td>19.78071</td>\n",
       "      <td>19.05765</td>\n",
       "      <td>8102</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>5.652162e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.459596</td>\n",
       "      <td>5020</td>\n",
       "      <td>55852</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.237662e+18</td>\n",
       "      <td>243.986637</td>\n",
       "      <td>25.738280</td>\n",
       "      <td>23.76761</td>\n",
       "      <td>23.79969</td>\n",
       "      <td>20.98318</td>\n",
       "      <td>19.80745</td>\n",
       "      <td>19.45579</td>\n",
       "      <td>3927</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>5.322364e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.591409</td>\n",
       "      <td>4727</td>\n",
       "      <td>55693</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          obj_ID       alpha      delta         u         g         r  \\\n",
       "0   1.237661e+18  135.689107  32.494632  23.87882  22.27530  20.39501   \n",
       "1   1.237665e+18  144.826101  31.274185  24.77759  22.83188  22.58444   \n",
       "2   1.237661e+18  142.188790  35.582444  25.26307  22.66389  20.60976   \n",
       "3   1.237663e+18  338.741038  -0.402828  22.13682  23.77656  21.61162   \n",
       "4   1.237680e+18  345.282593  21.183866  19.43718  17.58028  16.49747   \n",
       "5   1.237680e+18  340.995121  20.589476  23.48827  23.33776  21.32195   \n",
       "6   1.237679e+18   23.234926  11.418188  21.46973  21.17624  20.92829   \n",
       "7   1.237679e+18    5.433176  12.065186  22.24979  22.02172  20.34126   \n",
       "8   1.237661e+18  200.290475  47.199402  24.40286  22.35669  20.61032   \n",
       "9   1.237671e+18   39.149691  28.102842  21.74669  20.03493  19.17553   \n",
       "10  1.237680e+18  328.092076  18.220310  25.77163  22.52042  20.63884   \n",
       "11  1.237662e+18  243.986637  25.738280  23.76761  23.79969  20.98318   \n",
       "\n",
       "           i         z  run_ID  rerun_ID  cam_col  field_ID   spec_obj_ID  \\\n",
       "0   19.16573  18.79371    3606       301        2        79  6.543777e+18   \n",
       "1   21.16812  21.61427    4518       301        5       119  1.176014e+19   \n",
       "2   19.34857  18.94827    3606       301        2       120  5.152200e+18   \n",
       "3   20.50454  19.25010    4192       301        3       214  1.030107e+19   \n",
       "4   15.97711  15.54461    8102       301        3       137  6.891865e+18   \n",
       "5   20.25615  19.54544    8102       301        3       110  5.658977e+18   \n",
       "6   20.60826  20.42573    7773       301        2       462  1.246262e+19   \n",
       "7   19.48794  18.84999    7773       301        2       346  6.961443e+18   \n",
       "8   19.46490  18.95852    3716       301        5       108  7.459285e+18   \n",
       "9   18.81823  18.65422    5934       301        4       122  2.751763e+18   \n",
       "10  19.78071  19.05765    8102       301        3        27  5.652162e+18   \n",
       "11  19.80745  19.45579    3927       301        4       112  5.322364e+18   \n",
       "\n",
       "    class  redshift  plate    MJD  fiber_ID  \n",
       "0       0  0.634794   5812  56354       171  \n",
       "1       0  0.779136  10445  58158       427  \n",
       "2       0  0.644195   4576  55592       299  \n",
       "3       0  0.932346   9149  58039       775  \n",
       "4       0  0.116123   6121  56187       842  \n",
       "5       1  1.424659   5026  55855       741  \n",
       "6       1  0.586455  11069  58456       113  \n",
       "7       0  0.477009   6183  56210        15  \n",
       "8       0  0.660012   6625  56386       719  \n",
       "9       2 -0.000008   2444  54082       232  \n",
       "10      0  0.459596   5020  55852       525  \n",
       "11      0  0.591409   4727  55693       855  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert string labels into numbers: galaxy=0, qso=1, star=2\n",
    "def Encoder(df):\n",
    "    columnsToEncode = list(df.select_dtypes(include=['category','object']))\n",
    "    le = LabelEncoder()\n",
    "    for feature in columnsToEncode:\n",
    "        try:\n",
    "            df[feature] = le.fit_transform(df[feature])\n",
    "        except:\n",
    "            print('Error encoding '+feature)\n",
    "    return df\n",
    "\n",
    "num_df = Encoder(raw_data)\n",
    "num_df[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4707e89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23.87882   22.2753    20.39501   19.16573   18.79371    0.6347936]\n",
      " [24.77759   22.83188   22.58444   21.16812   21.61427    0.779136 ]\n",
      " [25.26307   22.66389   20.60976   19.34857   18.94827    0.6441945]\n",
      " ...\n",
      " [21.16916   19.26997   18.20428   17.69034   17.35221    0.1433656]\n",
      " [25.35039   21.63757   19.91386   19.07254   18.62482    0.4550396]\n",
      " [22.62171   21.79745   20.60115   20.00959   19.28075    0.5429442]]\n"
     ]
    }
   ],
   "source": [
    "# convert into two datasets: features, X (everything excluding \"class\" column), and labels, y (just the \"class\" column)\n",
    "#first convert pd dataframe to np array bc I know how to work with that better\n",
    "arr = num_df.to_numpy()\n",
    "type(arr)\n",
    "\n",
    "#arr[0:3]\n",
    "labels = arr[:,13]\n",
    "\n",
    "features = np.delete(arr, 13, axis=1)\n",
    "features = np.delete(arr, [0,1,2,8,9,10,11,12,13,15,16,17], axis=1)\n",
    "print(features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.30, random_state=40)\n",
    "#define training data\n",
    "#we'll select 70% of the data for this; we can just use the first .7 * 100,000 = 70,000 since they're not in any order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377836f7",
   "metadata": {},
   "source": [
    "### Part 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3410203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/utils/optimize.py:210: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/nalic/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#fit the models (35 of them) according to the given training data. We will try all 4 of the solvers that are \n",
    "#compatible with the multinomial case; for each solver, we will vary the penalty and the strength of the penalty \n",
    "#(\"C\"). (Note not all penalties are compatible with each solver).\n",
    "\n",
    "#models with lbfgs solver\n",
    "clf10 = LogisticRegression(penalty=None, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf121 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=100, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf122 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf123 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf124 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.1, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf125 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.01, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "\n",
    "#models with newton-cg solver\n",
    "clf20 = LogisticRegression(penalty=None, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='newton-cg', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf221 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=100, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='newton-cg', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf222 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='newton-cg', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf223 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='newton-cg', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf224 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.1, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='newton-cg', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf225 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.01, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='newton-cg', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "\n",
    "#models with sag solver\n",
    "clf30 = LogisticRegression(penalty=None, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='sag', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf321 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=100, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='sag', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf322 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='sag', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf323 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='sag', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf324 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.1, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='sag', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf325 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.01, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='sag', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "\n",
    "#models with saga solver\n",
    "clf40 = LogisticRegression(penalty=None, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='saga', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf411 = LogisticRegression(penalty='l1', dual=False, tol=0.0001, C=100, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='saga', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf412 = LogisticRegression(penalty='l1', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='saga', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf413 = LogisticRegression(penalty='l1', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='saga', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf414 = LogisticRegression(penalty='l1', dual=False, tol=0.0001, C=0.1, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='saga', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf415 = LogisticRegression(penalty='l1', dual=False, tol=0.0001, C=0.01, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='saga', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf421 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=100, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='saga', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf422 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='saga', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf423 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='saga', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf424 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.1, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='saga', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf425 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=0.01, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='saga', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_train, y_train)\n",
    "clf431 = LogisticRegression(penalty='elasticnet', dual=False, tol=0.0001, C=100, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='saga', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=0.5).fit(X_train, y_train)\n",
    "clf432 = LogisticRegression(penalty='elasticnet', dual=False, tol=0.0001, C=10, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='saga', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=0.5).fit(X_train, y_train)\n",
    "clf433 = LogisticRegression(penalty='elasticnet', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='saga', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=0.5).fit(X_train, y_train)\n",
    "clf434 = LogisticRegression(penalty='elasticnet', dual=False, tol=0.0001, C=0.1, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='saga', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=0.5).fit(X_train, y_train)\n",
    "clf435 = LogisticRegression(penalty='elasticnet', dual=False, tol=0.0001, C=0.01, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='saga', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=0.5).fit(X_train, y_train)\n",
    "\n",
    "###Predict class labels for samples in X\n",
    "#testdata_features = features[70000:, :]\n",
    "###I think the below definition is incorrect (trying to get rows 70,000 to 100,000 of the labels column)\n",
    "#testdata_labels = features[:, 70000:]\n",
    "#clf.predict(testdata_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03c07039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9340025492570628\n",
      "0.93708032312739\n",
      "0.9399381767488727\n",
      "0.9377403383729211\n",
      "0.9269294406347913\n",
      "0.9023131410166206\n",
      "0.952232361832623\n",
      "0.9526157830692933\n",
      "0.95198809700724\n",
      "0.9472865676871779\n",
      "0.940868105813759\n",
      "0.9035046931856399\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n",
      "0.24927826589032423\n"
     ]
    }
   ],
   "source": [
    "y_pred10 = clf10.predict(X_test)\n",
    "y_pred121 = clf121.predict(X_test) \n",
    "y_pred122 = clf122.predict(X_test) \n",
    "y_pred123 = clf123.predict(X_test)\n",
    "y_pred124 = clf124.predict(X_test)\n",
    "y_pred125 = clf125.predict(X_test) \n",
    "\n",
    "#models with newton-cg solver\n",
    "y_pred20 = clf20.predict(X_test) \n",
    "y_pred221 = clf221.predict(X_test) \n",
    "y_pred222 = clf222.predict(X_test) \n",
    "y_pred223 = clf223.predict(X_test)  \n",
    "y_pred224 = clf224.predict(X_test)  \n",
    "y_pred225 = clf225.predict(X_test)\n",
    "\n",
    "#models with sag solver\n",
    "y_pred30 = clf30.predict(X_test) \n",
    "y_pred321 = clf321.predict(X_test)\n",
    "y_pred322 = clf322.predict(X_test) \n",
    "y_pred323 = clf323.predict(X_test) \n",
    "y_pred324 = clf324.predict(X_test) \n",
    "y_pred325 = clf325.predict(X_test)\n",
    "\n",
    "#models with saga solver\n",
    "y_pred40 = clf40.predict(X_test) \n",
    "y_pred411 = clf411.predict(X_test) \n",
    "y_pred412 = clf412.predict(X_test) \n",
    "y_pred413 = clf413.predict(X_test) \n",
    "y_pred414 = clf414.predict(X_test) \n",
    "y_pred415 = clf415.predict(X_test)\n",
    "y_pred421 = clf421.predict(X_test) \n",
    "y_pred422 = clf422.predict(X_test) \n",
    "y_pred423 = clf423.predict(X_test) \n",
    "y_pred424 = clf424.predict(X_test) \n",
    "y_pred425 = clf425.predict(X_test) \n",
    "y_pred431 = clf431.predict(X_test) \n",
    "y_pred432 = clf432.predict(X_test) \n",
    "y_pred433 = clf433.predict(X_test) \n",
    "y_pred434 = clf434.predict(X_test) \n",
    "y_pred435 = clf435.predict(X_test)\n",
    "\n",
    "\n",
    "f11=sklearn.metrics.f1_score(y_test, y_pred10, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f12=sklearn.metrics.f1_score(y_test, y_pred121, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f13=sklearn.metrics.f1_score(y_test, y_pred122, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f14=sklearn.metrics.f1_score(y_test, y_pred123, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f15=sklearn.metrics.f1_score(y_test, y_pred124, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f16=sklearn.metrics.f1_score(y_test, y_pred125, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f17=sklearn.metrics.f1_score(y_test, y_pred20, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f18=sklearn.metrics.f1_score(y_test, y_pred221, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f19=sklearn.metrics.f1_score(y_test, y_pred222, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f110=sklearn.metrics.f1_score(y_test, y_pred223, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f111=sklearn.metrics.f1_score(y_test, y_pred224, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f112=sklearn.metrics.f1_score(y_test, y_pred225, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f113=sklearn.metrics.f1_score(y_test, y_pred30, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f114=sklearn.metrics.f1_score(y_test, y_pred321, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f115=sklearn.metrics.f1_score(y_test, y_pred322, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f116=sklearn.metrics.f1_score(y_test, y_pred323, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f117=sklearn.metrics.f1_score(y_test, y_pred324, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f118=sklearn.metrics.f1_score(y_test, y_pred325, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f119=sklearn.metrics.f1_score(y_test, y_pred40, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f120=sklearn.metrics.f1_score(y_test, y_pred411, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f121=sklearn.metrics.f1_score(y_test, y_pred412, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f122=sklearn.metrics.f1_score(y_test, y_pred413, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f123=sklearn.metrics.f1_score(y_test, y_pred414, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f124=sklearn.metrics.f1_score(y_test, y_pred415, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f125=sklearn.metrics.f1_score(y_test, y_pred421, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f126=sklearn.metrics.f1_score(y_test, y_pred422, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f127=sklearn.metrics.f1_score(y_test, y_pred423, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f128=sklearn.metrics.f1_score(y_test, y_pred424, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f129=sklearn.metrics.f1_score(y_test, y_pred425, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f130=sklearn.metrics.f1_score(y_test, y_pred431, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f131=sklearn.metrics.f1_score(y_test, y_pred432, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f132=sklearn.metrics.f1_score(y_test, y_pred433, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f133=sklearn.metrics.f1_score(y_test, y_pred434, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "f134=sklearn.metrics.f1_score(y_test, y_pred435, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "\n",
    "print(f11)\n",
    "print(f12)\n",
    "print(f13)\n",
    "print(f14)\n",
    "print(f15)\n",
    "print(f16)\n",
    "print(f17)\n",
    "print(f18)\n",
    "print(f19)\n",
    "print(f110)\n",
    "print(f111)\n",
    "print(f112)\n",
    "print(f113)\n",
    "print(f114)\n",
    "print(f115)\n",
    "print(f116)\n",
    "print(f117)\n",
    "print(f118)\n",
    "print(f119)\n",
    "print(f120)\n",
    "print(f121)\n",
    "print(f122)\n",
    "print(f123)\n",
    "print(f124)\n",
    "print(f125)\n",
    "print(f126)\n",
    "print(f127)\n",
    "print(f128)\n",
    "print(f129)\n",
    "print(f130)\n",
    "print(f131)\n",
    "print(f132)\n",
    "print(f133)\n",
    "print(f134)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "652583a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies of the lbfgs solvers: \n",
      "0.9416666666666667\n",
      "0.9449\n",
      "0.9476\n",
      "0.9451666666666667\n",
      "0.9342333333333334\n",
      "0.9104\n",
      "\n",
      "\n",
      "Accuracies of the Newton-cg solvers: \n",
      "0.9585333333333333\n",
      "0.9589\n",
      "0.9583\n",
      "0.9538666666666666\n",
      "0.9478666666666666\n",
      "0.9135333333333333\n",
      "\n",
      "\n",
      "Accuracies of the sag solvers: \n",
      "0.5972333333333333\n",
      "0.5972333333333333\n",
      "0.5972333333333333\n",
      "0.5972333333333333\n",
      "0.5972333333333333\n",
      "0.5972333333333333\n",
      "\n",
      "\n",
      "Accuracies of the saga solvers: \n",
      "0.5972333333333333\n",
      "0.5972333333333333\n",
      "0.5972333333333333\n",
      "0.5972333333333333\n",
      "0.5972333333333333\n",
      "0.5972333333333333\n",
      "0.5972333333333333\n",
      "0.5972333333333333\n",
      "0.5972333333333333\n",
      "0.5972333333333333\n",
      "0.5972333333333333\n",
      "0.5972333333333333\n",
      "0.5972333333333333\n",
      "0.5972333333333333\n",
      "0.5972333333333333\n",
      "0.5972333333333333\n"
     ]
    }
   ],
   "source": [
    "#Return the mean accuracies of the different models on the given test data and labels.    **this is training not test\n",
    "print(\"Accuracies of the lbfgs solvers: \")\n",
    "print(clf10.score(X_test, y_test))\n",
    "print(clf121.score(X_test, y_test))\n",
    "print(clf122.score(X_test, y_test))\n",
    "print(clf123.score(X_test, y_test))\n",
    "print(clf124.score(X_test, y_test))\n",
    "print(clf125.score(X_test, y_test))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Accuracies of the Newton-cg solvers: \")\n",
    "print(clf20.score(X_test, y_test))\n",
    "print(clf221.score(X_test, y_test))\n",
    "print(clf222.score(X_test, y_test))\n",
    "print(clf223.score(X_test, y_test))\n",
    "print(clf224.score(X_test, y_test))\n",
    "print(clf225.score(X_test, y_test))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Accuracies of the sag solvers: \")\n",
    "print(clf30.score(X_test, y_test))\n",
    "print(clf321.score(X_test, y_test))\n",
    "print(clf322.score(X_test, y_test))\n",
    "print(clf323.score(X_test, y_test))\n",
    "print(clf324.score(X_test, y_test))\n",
    "print(clf325.score(X_test, y_test))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Accuracies of the saga solvers: \")      \n",
    "print(clf40.score(X_test, y_test))\n",
    "print(clf421.score(X_test, y_test))\n",
    "print(clf412.score(X_test, y_test))\n",
    "print(clf413.score(X_test, y_test))\n",
    "print(clf414.score(X_test, y_test))\n",
    "print(clf415.score(X_test, y_test))\n",
    "print(clf421.score(X_test, y_test))\n",
    "print(clf422.score(X_test, y_test))\n",
    "print(clf423.score(X_test, y_test))\n",
    "print(clf424.score(X_test, y_test))\n",
    "print(clf425.score(X_test, y_test))\n",
    "print(clf431.score(X_test, y_test))\n",
    "print(clf432.score(X_test, y_test))\n",
    "print(clf433.score(X_test, y_test))\n",
    "print(clf434.score(X_test, y_test))\n",
    "print(clf435.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5498f08e",
   "metadata": {},
   "source": [
    "So, we see that model #221 - that is, the model using the Newton-cg solver with an l2 regularization term of strength 100 (so a relatively small strength), yields the highest accuracy and therefore performs best (according to this metric, at least). The second and third highest accuracies were achieved by the Newton-cg with no regularization term, and the Newton-cg with an l2 regularization term of strength 10, respectively. This makes sense since those two are the most simliar to the aforementioned highest scoring model. \n",
    "\n",
    "More generally, sag and saga-based solvers performed poorly (accuracies of around 59% for each of them), while the Newton-cg and lbfgs based models performed best (accuracies ranging from ~91% to ~96%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1182095",
   "metadata": {},
   "source": [
    " To be able to visually observe how each model separates the data to classify it into the different classes, we will use PCA in order to reduce the number of dimensions to 2. This will then allow us to plot a decision surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c65931a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.952):\n",
      "{'pca__n_components': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hc/_g40sknj4mxbq0bmp0c446n00000gq/T/ipykernel_1999/4100156770.py:42: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  best_clfs = results.groupby(components_col).apply(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define a pipeline to search for the best combination of PCA truncation\n",
    "# and classifier regularization.\n",
    "pca = PCA()\n",
    "# Define a Standard Scaler to normalize inputs\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# set the tolerance to a large value to make the example faster\n",
    "logistic = LogisticRegression(max_iter=10000, tol=0.1)\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"pca\", pca), (\"logistic\", logistic)])\n",
    "\n",
    "X_digits, y_digits = X_train, y_train\n",
    "# Parameters of pipelines can be set using '__' separated parameter names:\n",
    "param_grid = {\n",
    "    \"pca__n_components\": [1, 2, 3, 4, 5, 6],\n",
    "}\n",
    "search = GridSearchCV(pipe, param_grid, n_jobs=2)\n",
    "search.fit(X_digits, y_digits)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)\n",
    "\n",
    "# Plot the PCA spectrum\n",
    "pca.fit(X_digits)\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True, figsize=(6, 6))\n",
    "ax0.plot(\n",
    "    np.arange(1, pca.n_components_ + 1), pca.explained_variance_ratio_, \"+\", linewidth=2)\n",
    "ax0.set_ylabel(\"PCA explained variance ratio\")\n",
    "\n",
    "ax0.axvline(\n",
    "    search.best_estimator_.named_steps[\"pca\"].n_components,\n",
    "    linestyle=\":\",\n",
    "    label=\"n_components chosen\",)\n",
    "ax0.legend(prop=dict(size=12))\n",
    "\n",
    "# For each number of components, find the best classifier results\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "components_col = \"param_pca__n_components\"\n",
    "best_clfs = results.groupby(components_col).apply(\n",
    "    lambda g: g.nlargest(1, \"mean_test_score\"))\n",
    "\n",
    "best_clfs.plot(\n",
    "    x=components_col, y=\"mean_test_score\", yerr=\"std_test_score\", legend=False, ax=ax1)\n",
    "ax1.set_ylabel(\"Classification accuracy (val)\")\n",
    "ax1.set_xlabel(\"n_components\")\n",
    "\n",
    "plt.xlim(0, 7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.title('Decision Boundary after PCA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2069de24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99783568 0.00152232]\n",
      "[17374.43680086   678.63079561]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DecisionBoundaryDisplay' object has no attribute 'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m clf221 \u001b[38;5;241m=\u001b[39m LogisticRegression(penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m'\u001b[39m, dual\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, intercept_scaling\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton-cg\u001b[39m\u001b[38;5;124m'\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultinomial\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, warm_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, l1_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39mfit(X_new, y_train)\n\u001b[1;32m      8\u001b[0m disp \u001b[38;5;241m=\u001b[39m DecisionBoundaryDisplay\u001b[38;5;241m.\u001b[39mfrom_estimator(clf221, X_new, xlabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature1\u001b[39m\u001b[38;5;124m\"\u001b[39m, ylabel \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature2\u001b[39m\u001b[38;5;124m\"\u001b[39m, response_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mdisp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtitle\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecision Boundary after application of PCA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DecisionBoundaryDisplay' object has no attribute 'title'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAGwCAYAAACpYG+ZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4CUlEQVR4nO3deXxU5b3H8e+wZAjJZCAJ2SCEIFGLQUSwLEUDtqBUsS51QxFar9UiyHIRxRW8QkQr1dYrXtte1LYWN7RWLBKvEuQGlPWCuAEGgpKYgpAENBMgz/0DM84KGUhmO5/36zWvl3POk8nvCS/Dl+d3nnNsxhgjAAAAC2gT6QIAAADCheADAAAsg+ADAAAsg+ADAAAsg+ADAAAsg+ADAAAsg+ADAAAso12kC4g2jY2N2r17txwOh2w2W6TLAQAAzWCMUV1dnXJyctSmTfB1HYKPj927dys3NzfSZQAAgBOwa9cudevWLeh5go8Ph8MhSZr90mvq0DEpwtUAAIAmH+zfqbqEKp3epVJDO21TRofOkqTuHc9QXV29+p4xx/33eDAEHx9N7a0OHZOUmETwAQAg0sr27ZAk1Xfar76ZX6uo805ldchUXlIfv7HHu0wlZi5uXrBggc4880ylpKQoJSVFgwcP1j//+U/3eWOMZs2apZycHCUmJmrYsGHasmVLBCsGAAChKNu3I+CrLmG3UjIOaMQpB1XU+TNldUgNGHqaI2aCT7du3fTQQw9p7dq1Wrt2rc4//3z97Gc/c4ebhx9+WPPnz9cTTzyhNWvWKCsrSyNGjFBdXV2EKwcAAMfjGXB8X70zd+uSrNc11LH9pEKPJNli+ensqampeuSRR/TLX/5SOTk5mjJliu644w5JksvlUmZmpubNm6ebb7456Ge4XC65XC73+9raWuXm5mrekhJaXQAAtLKmNlZKxgE57Z+oa7LTb0yv9muOG3jqauvVs/u9qqmpUUpKStBxMXmNz5EjR/TSSy/p4MGDGjx4sMrLy1VVVaWRI0e6x9jtdhUVFamsrOyYwae4uFizZ88OR9kAAMBD0ypP104p6p1WqV7tj7ax/J3cKo+nmAo+mzdv1uDBg1VfX6/k5GS9+uqr6t27t8rKyiRJmZmZXuMzMzO1c+fOY37mzJkzNW3aNPf7phUfAADQeppCT+/M3SrqvPy7wNNyASeYmAo+p512mjZu3Kj9+/frlVde0bhx41RaWuo+73sltzHmuFd32+122e32VqkXAAB482xt5dp3n/TFyqGKqeCTkJCgXr16SZIGDBigNWvW6PHHH3df11NVVaXs7Gz3+Orqar9VIAAAEBmeqzxdk53u1la4Qo8UQ7u6AjHGyOVyKT8/X1lZWSopKXGfa2hoUGlpqYYMGRLBCgEAgOTb2vqsRXZonYiYWfG56667NGrUKOXm5qqurk6LFi3S8uXLtXTpUtlsNk2ZMkVz585VQUGBCgoKNHfuXHXs2FFjxoyJdOkAAFhCUxsrkEi1tnzFTPD56quvNHbsWFVWVsrpdOrMM8/U0qVLNWLECEnSjBkz9O2332rChAnat2+fBg4cqGXLlh331tUAAODkee7Q8tW0TT0SrS1fMX0fn9ZQW1srp9PJfXwAAGgm32t3fDXdh0dSq4WeuL6PDwAAiLxgO7T8RXaVxxPBBwAAhCwadmidCIIPAAAIie8OraOBpyjSZTULwQcAADSL+wLmjJSo2KF1Igg+AADAS7Bt6d+3tg7GTGvLF8EHAAC4HWtbuvcqT2y0tnwRfAAAgF8bq2vyQb8xsbrK44ngAwCAxXnv0DqooY49kvYEGBnboUci+AAAYGmBd2jFdrg5FoIPAAAWFA87tE4EwQcAAIsJ3NqK/9AjEXwAALCMpm3qVmpt+SL4AAAQZ451H56unazV2vJF8AEAII4c7z48Vmtt+SL4AAAQB3zbWPF6H56TRfABACDGea7yDEr7/nES/qwdeiSCDwAAMc1/h9Z2EXCCI/gAABCD2KF1Ygg+AADEmGCtLULP8RF8AACIUsfaln50lWf5d9fyEHqai+ADAECU8WxjBduWTmvrxBB8AACIIr5tLIlt6S2J4AMAQJTwflL68iBb0iVaWyeO4AMAQIQ1tbZSMg7QxmplBB8AACLIs7XVO62SNlYrI/gAABAhgVtbhJ7WRPABACDMaG1FDsEHAIBWcrz78HRNdtLaCjOCDwAArcDz2h1fnqs8tLbCi+ADAEAL8m9jLQ84jlWeyGgT6QKaq7i4WOecc44cDocyMjJ06aWX6tNPP/UaM378eNlsNq/XoEGDIlQxAMBqmlZ5cnPXqndapXtVZ2Bakd+L0BMZMRN8SktLdeutt2r16tUqKSnR4cOHNXLkSB086H1HywsvvFCVlZXu15tvvhmhigEAVuK9Q+szDXVsZ1UnCsVMq2vp0qVe7xcuXKiMjAytW7dO5513nvu43W5XVlZWuMsDAFgUO7RiS8wEH181NTWSpNRU79t5L1++XBkZGerUqZOKioo0Z84cZWRkBP0cl8sll8vlfl9bW9s6BQMA4o7nKg87tGJDTAYfY4ymTZumoUOHqrCw0H181KhRuvLKK5WXl6fy8nLde++9Ov/887Vu3TrZ7faAn1VcXKzZs2eHq3QAQAw63rb071d5isJbGEJmM8aYSBcRqltvvVVLlizRypUr1a1bt6DjKisrlZeXp0WLFunyyy8POCbQik9ubq7mLSlRYlJSi9cOAIgdx9qSLklO+ye0tqJEXW29ena/VzU1NUpJCfznJcXgis+kSZP0+uuva8WKFccMPZKUnZ2tvLw8bd26NegYu90edDUIAGBd3m2sgwHH0NqKPTETfIwxmjRpkl599VUtX75c+fn5x/2avXv3ateuXcrOzg5DhQCAeOG7Q+vojQb90dqKPTETfG699VY9//zz+vvf/y6Hw6GqqipJktPpVGJiog4cOKBZs2bpiiuuUHZ2tnbs2KG77rpL6enpuuyyyyJcPQAgFrhbWxkp7NCKUzETfBYsWCBJGjZsmNfxhQsXavz48Wrbtq02b96s5557Tvv371d2draGDx+uF154QQ6HIwIVAwBiiW9rizZWfIqZ4HO8a7ATExP11ltvhakaAEA8CdTaoo0Vn2Im+AAA0NJobVkPwQcAEPeOdx+erskHNdSxRzwpPf4RfAAAcasp8DQFnEBY5bEWgg8AIC553nzQs43lj9BjJQQfAEDc8d2hRRsLTQg+AIC44dvaoo0FXwQfAEBcCNbaIvTAE8EHABDzaG2huQg+AICYEGxLukRrC81H8AEARD3PNlYgg9J4xASah+ADAIhqvm2sQIY6tovWFpqD4AMAiErBdmgFQuBBcxF8AABRx7O1RRsLLYngAwCIKt5PSl/+3SoPoQctg+ADAIgK3HwQ4UDwAQBEHK0thAvBBwAQNk0Bx0+CaG0hLAg+AIBW19TGSsk4oFz7bnVNdvqNYZUH4UDwAQC0Ks82Vu+0SnfA8UfoQesj+AAAWg07tBBtCD4AgBbn29pihxaiBcEHANCivB8x4eTaHUQVgg8AoMV4t7Y+o7WFqEPwAQCEpKmNFQitLUQ7gg8AoNk8d2j5cto/obWFqEfwAQA0i/e1Owf9zn8feIoiUB3QPAQfAMAxBduh5Y9VHkQ/gg8AICh2aCHeEHwAAAEF2qFFGwuxjuADAPDivoA5I4UdWog7bSJdQHMVFxfrnHPOkcPhUEZGhi699FJ9+umnXmOMMZo1a5ZycnKUmJioYcOGacuWLRGqGACiW9m+HQFfTas8vdMqCT2IOzETfEpLS3Xrrbdq9erVKikp0eHDhzVy5EgdPPj9zoKHH35Y8+fP1xNPPKE1a9YoKytLI0aMUF1dXQQrB4Do0xRwUjIO+L2aWltDHds1MK2I0IO4YjPGmEgXcSL+9a9/KSMjQ6WlpTrvvPNkjFFOTo6mTJmiO+64Q5LkcrmUmZmpefPm6eabb27W59bW1srpdGrekhIlJiW15hQAIOw878PTdN8dX73ar2GVBzGnrrZePbvfq5qaGqWk+N9nqknMXuNTU1MjSUpNPbqlsry8XFVVVRo5cqR7jN1uV1FRkcrKyoIGH5fLJZfL5X5fW1vbilUDQOT43odnqGOPpD0BRhJ6EL9iMvgYYzRt2jQNHTpUhYWFkqSqqipJUmZmptfYzMxM7dy5M+hnFRcXa/bs2a1XLABEgcA7tAg3sJ6YucbH08SJE7Vp0yb97W9/8ztns9m83htj/I55mjlzpmpqatyvXbt2tXi9ABApZft26K2DZV7X7hB6YGUxt+IzadIkvf7661qxYoW6devmPp6VlSXp6MpPdna2+3h1dbXfKpAnu90uu93eegUDQIQEbm0RemBtMbPiY4zRxIkTtXjxYr3zzjvKz8/3Op+fn6+srCyVlJS4jzU0NKi0tFRDhgwJd7kAEDG+29KbdmjlJfUh9MDyYmbF59Zbb9Xzzz+vv//973I4HO5repxOpxITE2Wz2TRlyhTNnTtXBQUFKigo0Ny5c9WxY0eNGTMmwtUDQMtreoaWr6ZdW9x8EPAXM8FnwYIFkqRhw4Z5HV+4cKHGjx8vSZoxY4a+/fZbTZgwQfv27dPAgQO1bNkyORyOMFcLAK3Lc1u6r1w7rS0gmJi9j09r4T4+AKJZ0yqP54NDfXEfHlhR3N/HBwCsxnOVZ1DaQfeT0v0ReoBgCD4AEAP8d2htFwEHCB3BBwCimG9ri4uVgZND8AGAKBWstUXoAU4cwQcAIuxY29KPrvIs/+5aHkIPcLIIPgAQIZ5trGDb0mltAS2L4AMAEeDbxpIO+o2htQW0PIIPAISZ9+MklgfZki7R2gJaHsEHAMKkqbWVknGANhYQIQQfAAgDz9ZW77RK2lhAhBB8AKCVBW5tEXqASCD4AEArobUFRB+CDwCcpOPdh6drspPWFhAlCD4AcBI8r93x5bnKQ2sLiA4EHwA4Ab5trK7J3IcHiAUEHwAIkfeT0r9vY/kj9ADRhuADACHw3qFFGwuINQQfAGgGdmgB8YHgAwDHEay1RegBYg/BBwC+c7xt6d+v8hSFtzAALYbgA8Dy3FvSM/y3pEuitQXEEYIPAEvzbmP5b0mX2JYOxBOCDwDLCrxDyx+tLSB+EHwAWI5na4s2FmAtBB8AluLb2qKNBVgLwQeAZQRqbdHGAqyF4AMg7tHaAtCE4AMgbhzvPjxdkw9qqGOPeMQEYF0EHwAxrynw1CXsVtdO/vfiYZUHQBOCD4CY5m5jdTraxgp0Lx4uYAbQhOADIGb57tA62sbaE2AkoQfAUW0iXUAoVqxYodGjRysnJ0c2m02vvfaa1/nx48fLZrN5vQYNGhSZYgG0mrJ9O/x2aA11bFdeUp+gLwCQYiz4HDx4UH379tUTTzwRdMyFF16oyspK9+vNN98MY4UAWltT4EnJOOCzLZ1wA+D4YqrVNWrUKI0aNeqYY+x2u7Kyspr9mS6XSy6Xy/2+trb2hOsD0LoCt7YIPQCaL6aCT3MsX75cGRkZ6tSpk4qKijRnzhxlZGQEHV9cXKzZs2eHsUIAxxJsS7qkADcfJPAACE1cBZ9Ro0bpyiuvVF5ensrLy3Xvvffq/PPP17p162S32wN+zcyZMzVt2jT3+9raWuXm5oarZAAePHdoBTIojUdMADg5cRV8rr76avd/FxYWasCAAcrLy9OSJUt0+eWXB/wau90eNBQBCB/fNlYgQx3bRWsLwMmIq+DjKzs7W3l5edq6dWukSwEQhOfNBz3bWIEQeACcrLgOPnv37tWuXbuUnZ0d6VIABODZ2qKNBSAcYir4HDhwQNu2bXO/Ly8v18aNG5WamqrU1FTNmjVLV1xxhbKzs7Vjxw7dddddSk9P12WXXRbBqgEE4n0fnuXfrfIQegC0rpgKPmvXrtXw4cPd75suSh43bpwWLFigzZs367nnntP+/fuVnZ2t4cOH64UXXpDD4YhUyQB8BGttEXgAhENMBZ9hw4bJGBP0/FtvvRXGagCEitYWgEiLqeADIDYEuxcPrS0AkUbwAdBimgJPSsaBgOdz7bS2AEQWwQdAi/C+D48z4BhaWwAijeAD4KT5Pik92H14aG0BiDSCD4AT5tnaoo0FIBYQfACcEN/WFm0sALGA4AMgZIFbW4QeANGP4AMgoGBb0iVaWwBiF8EHgB/PGw36cto/obUFIGYRfAB48b5256Df+e8DT1EEqgOAk0PwASDJY5UnI8WrjeWPVR4AsYvgA8BvlYc2FoB4RfABLC7QDi3aWADiFcEHsKhgrS1WeQDEM4IPYEG0tgBYFcEHiGPB7sVDawuAVRF8gDjk2cYKhNYWAKsi+ABxxr+NtcZvDI+YAGBVBB8gjrBDCwCOjeADxAF2aAFA8xB8gBjn29oa6tgj2lgAEFhIwWfJkiV69dVXlZqaql/+8pc6/fTT3ef27dunK664Qu+8806LFwnAX9OOLf/WFoEHAIJp09yBzz//vH72s5+pqqpKq1atUr9+/fTXv/7Vfb6hoUGlpaWtUiRgZWX7dgR81SXsVkrGAUIPAISg2Ss+v/nNb/Tb3/5WkyZNkiS9/PLL+sUvfqH6+nrdeOONrVYgYGXua3c6+W9Lz7XT2gKAUDU7+Hz22We6+OKL3e9//vOfKz09XZdccokOHTqkyy67rFUKBKzIt43VNfmg3xjutgwAoWt28ElJSdFXX32l/Px897Fhw4bpH//4hy6++GJ98cUXrVIgYDWeqzyD0r5/nIQ/Qg8AhKrZweeHP/yh/vnPf2rQoEFex4uKitzhB8DJ8d+htV0EHABoOc0OPlOnTlVZWVnAc8OGDdMbb7yhZ599tsUKA6yEHVoAEB42Y4yJdBHRpLa2Vk6nU/OWlCgxKSnS5cACPFtbvdMq1av9GkIPAISorrZePbvfq5qaGqWkBH5OoRTCdnZP27dv1z333KNrr71W1dXVkqSlS5dqy5YtJ1YtYFGera1Lsl7XUMd2Qg8AtKKQg09paan69Omj999/X4sXL9aBAwckSZs2bdL999/f4gV6WrFihUaPHq2cnBzZbDa99tprXueNMZo1a5ZycnKUmJioYcOGEcYQccHuwxP4uVp9CD0A0IpCDj533nmnHnzwQZWUlCghIcF9fPjw4Vq1alWLFufr4MGD6tu3r5544omA5x9++GHNnz9fTzzxhNasWaOsrCyNGDFCdXV1rVoXEIznjQZzc9f6vUaccpDreQAgjEJ+VtfmzZv1/PPP+x3v0qWL9u7d2yJFBTNq1CiNGjUq4DljjB577DHdfffduvzyyyVJzz77rDIzM/X888/r5ptvDvh1LpdLLpfL/b62trblC4clea/oLA+yJZ2bDwJAOIUcfDp16qTKykqv+/lI0oYNG9S1a9cWKyxU5eXlqqqq0siRI93H7Ha7ioqKVFZWFjT4FBcXa/bs2eEqExbQtEMrJeMAT0oHgCgTcqtrzJgxuuOOO1RVVSWbzabGxkb97//+r6ZPn64bbrihNWpslqqqKklSZmam1/HMzEz3uUBmzpypmpoa92vXrl2tWifim9cztNIqCT0AEGVCXvGZM2eOxo8fr65du8oYo969e+vIkSMaM2aM7rnnntaoMSQ2m83rvTHG75gnu90uu93e2mXBAgK3tgg9ABBNQgo+xhjt3r1bf/jDH/Qf//EfWr9+vRobG9WvXz8VFBS0Vo3NkpWVJenoyk92drb7eHV1td8qENCSaG0BQOwIOfgUFBRoy5YtKigoUM+ePVurrpDl5+crKytLJSUl6tevnySpoaFBpaWlmjdvXoSrQzxoCji+vn/EhJMHhwJAlAsp+LRp00YFBQXau3dvRFZ4Dhw4oG3btrnfl5eXa+PGjUpNTVX37t01ZcoUzZ07VwUFBSooKNDcuXPVsWNHjRkzJuy1Ir543l3Zl+cqD60tAIhuIV/j8/DDD+v222/XggULVFhY2Bo1BbV27VoNHz7c/X7atGmSpHHjxumZZ57RjBkz9O2332rChAnat2+fBg4cqGXLlsnhcIS1TsQP3zZW1+SDfmNY5QGA2BHys7o6d+6sb775RocPH1ZCQoISExO9zn/99dctWmC48awuNPF+UrrT/QytQAg9ABBZzX1WV8grPo899tjJ1AXEhMCPkyiKdFkAgJMUcvAZN25ca9QBRAV2aAFAfAs5+FRUVBzzfPfu3U+4GCCS/FtbhB4AiDchB58ePXoc84aAR44cOamCgEigtQUA1hBy8NmwYYPX+0OHDmnDhg2aP3++5syZ02KFAS2tqY1Vl7Db71zXjBRaWwBgASEHn759+/odGzBggHJycvTII4+4n4wORBPfNpa/g7S2AMACQg4+wZx66qlas2ZNS30c0GICtbECobUFAPEv5OBTW1vr9d4Yo8rKSs2aNSviz+sCPLnvtkwbCwDwnZCDT6dOnQI+AT03N1eLFi1qscKAk+Hd2qKNBQA4KuTg8+6773q9b9Omjbp06aJevXqpXbsW65xF3IbPvtCQfqdFugycAHZoAQCCCTmp2Gw2DRkyxC/kHD58WCtWrNB5553XYsVF0r+qa7X2k10acHpupEtBM9HaAgAcT8jBZ/jw4aqsrFRGRobX8ZqaGg0fPjxu7uPTwyTri69qtFYi/ESZpm3pvjxbW0Mde8ST0gEAvkIOPsaYgDcw3Lt3r5Li6KGeA7rnKKF6v/yfxY1I8bwPT9dO/g+gY5UHAHA8zQ4+TffnsdlsGj9+vOx2u/vckSNHtGnTJg0ZMqTlKwTk0cbqdLSN1TXZP5JyATMA4HiaHXyczqM3fTPGyOFwKDEx0X0uISFBgwYN0k033dTyFcLyfHdoHW1j7QkwktADADi2ZgefhQsXSjr6rK7p06fHVVsL0cmzteW9Q4twAwA4MSFf43P//fe3Rh2AF9/WFqEHANASTujGOy+//LJefPFFVVRUqKGhwevc+vXrW6QwWFfg1hahBwBw8tqE+gW/+93v9Itf/EIZGRnasGGDfvjDHyotLU2ff/65Ro0a1Ro1Ik6V7dsR8OXZ2hrq2K68pD6EHgBAiwh5xefJJ5/U008/rWuvvVbPPvusZsyYoZ49e+q+++7T119/3Ro1Is543mgwkEFpPGICANA6Qg4+FRUV7m3riYmJqqurkySNHTtWgwYN0hNPPNGyFSKu+LaxAhnq2C5aWwCA1hBy8MnKytLevXuVl5envLw8rV69Wn379lV5ebmMMa1RI+JAsB1agRB4AACtJeTgc/755+sf//iHzj77bN14442aOnWqXn75Za1du9Z9k0PAk+cOLdpYAIBICjn4PP3002psbJQk3XLLLUpNTdXKlSs1evRo3XLLLS1eIGKb98XKy79b5SH0AAAiI+Tg06ZNG7Vp8/1msKuuukpXXXVVixaF2MfNBwEA0Sjk7eyS9N577+n666/X4MGD9eWXX0qS/vznP2vlypUtWhxiU9MqT0rGAY045SChBwAQNUJe8XnllVc0duxYXXfdddqwYYNcLpckqa6uTnPnztWbb77Z4kUiOjWt6viitQUAiFYhB58HH3xQTz31lG644QYtWrTIfXzIkCF64IEHWrQ4RKemwJOScSDgeR4xAQCIViEHn08//VTnnXee3/GUlBTt37+/JWpCFPO+D48z4Bh2bQEAolXIwSc7O1vbtm1Tjx49vI6vXLlSPXv2bKm6EIV8HycR7D48tLYAANEq5OBz8803a/Lkyfrv//5v2Ww27d69W6tWrdL06dN13333tUaNzTZr1izNnj3b61hmZqaqqqoiVFF88Gxt0cYCAMSyZgWfTZs2qbCwUG3atNGMGTNUU1Oj4cOHq76+Xuedd57sdrumT5+uiRMntna9x3XGGWfo7bffdr9v27ZtBKuJfb6tLdpYAIBY1qzg069fP1VWViojI0M9e/bUmjVrdNddd+njjz9WY2OjevfureTk5NautVnatWunrKysSJcRFwK3tgg9AIDY1azg06lTJ5WXlysjI0M7duxQY2OjkpKSNGDAgNauL2Rbt25VTk6O7Ha7Bg4cqLlz5x7z2iOXy+Xeki9JtbW14SgzagTbki7R2gIAxJ9mBZ8rrrhCRUVFys7Ols1m04ABA4K2kD7//PMWLTAUAwcO1HPPPadTTz1VX331lR588EENGTJEW7ZsUVpaWsCvKS4u9rsuyCo8n6Hly2n/hNYWACDu2EwzH6m+dOlSbdu2TbfddpseeOABORyOgOMmT57cogWejIMHD+qUU07RjBkzNG3atIBjAq345ObmasGT/9Sm6v06mNVGA07PDVfJYXO8bem92q8h8AAAYkZdbb16dr9XNTU1Sknx/wd9k2bv6rrwwgslSevWrdPkyZODBp9okpSUpD59+mjr1q1Bx9jtdtnt9jBWFVnuVZ6MFK82lj9CDwAg/oS8nX3hwoWtUUercLlc+vjjj3XuuedGupSo4L3Kc5A2FgDAckIOPtFs+vTpGj16tLp3767q6mo9+OCDqq2t1bhx4yJdWsQF2qGVl1QU6bIAAAiruAo+X3zxha699lrt2bNHXbp00aBBg7R69Wrl5eVFurSICdbaYpUHAGBFcRV8PB+aClpbAAD4iqvgY1XB7sVDawsAAG8Enxjm2cYKhNYWAADeCD4xyreNFchQxx6xLR0AgO8RfGJMU1vL/xla/gg8AAB4I/jEEM9HTNDGAgAgdASfGOHb2qKNBQBA6Ag+US5Ya4vAAwBA6Ag+UeJYW9JpbQEA0DIIPlHA89odX7l2WlsAALQUgk8E+baxAm1L527LAAC0HIJPhHiu8gxK+/5xEv4IPQAAtBSCTwT479DaLgIOAACtj+ATRuzQAgAgsgg+YRKstUXoAQAgfAg+YeDZ2irqvPy7a3kIPQAAhBvBp4UEuw+PRGsLAIBoQfBpAce6D48kWlsAAEQJgs9J8t2h5atX+zW0tgAAiBIEnxPU1NpKyTjg9TgJfwQeAACiBcHnBHi2tnqnVdLGAgAgRhB8QsQOLQAAYhfBp5mCtbYIPAAAxA6CTzN4X8DspLUFAECMIvgEsbZit75IPKJv2zXKkXDA6z48tLYAAIhNBJ9jyMx0am/2Lm4+CABAnCD4BLHDdkCH2h3SD5zlKuq8k9ADAEAcaBPpAqKZI/uAUjrYCT0AAMQJgk8QXTKOPn6ia7IzwpUAAICWQvABAACWQfABAACWEZfB58knn1R+fr46dOig/v3767333ot0SQAAIArEXfB54YUXNGXKFN19993asGGDzj33XI0aNUoVFRWRLg0AAERY3AWf+fPn68Ybb9S//du/6Qc/+IEee+wx5ebmasGCBZEuDQAARFhcBZ+GhgatW7dOI0eO9Do+cuRIlZWVBfwal8ul2tparxcAAIhPcRV89uzZoyNHjigzM9PreGZmpqqqqgJ+TXFxsZxOp/uVm5sbjlIBAEAExFXwaWKz2bzeG2P8jjWZOXOmampq3K9du3aFo0QAABABcfXIivT0dLVt29Zvdae6utpvFaiJ3W6X3W4PR3kAACDC4mrFJyEhQf3791dJSYnX8ZKSEg0ZMiRCVQEAgGgRVys+kjRt2jSNHTtWAwYM0ODBg/X000+roqJCt9xyS6RLAwAAERZ3wefqq6/W3r179cADD6iyslKFhYV68803lZeXF+nSAABAhMVd8JGkCRMmaMKECZEuAwAARJm4usYHAADgWAg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMgg+AADAMuIq+PTo0UM2m83rdeedd0a6LAAAECXaRbqAlvbAAw/opptucr9PTk6OYDUAACCaxF3wcTgcysrKavZ4l8sll8vlfl9bW9saZQEAgCgQV60uSZo3b57S0tJ01llnac6cOWpoaDjm+OLiYjmdTvcrNzc3TJUCAIBwi6sVn8mTJ+vss89W586d9cEHH2jmzJkqLy/XH//4x6BfM3PmTE2bNs39vra2lvADAECcivrgM2vWLM2ePfuYY9asWaMBAwZo6tSp7mNnnnmmOnfurJ///OfuVaBA7Ha77HZ7i9YMAACiU9QHn4kTJ+qaa6455pgePXoEPD5o0CBJ0rZt24IGHwAAYB1RH3zS09OVnp5+Ql+7YcMGSVJ2dnZLlgQAAGJU1Aef5lq1apVWr16t4cOHy+l0as2aNZo6daouueQSde/ePdLlAQCAKBA3wcdut+uFF17Q7Nmz5XK5lJeXp5tuukkzZsyIdGkAACBKxE3wOfvss7V69epIlwEAAKJY3N3HBwAAIBiCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsAyCDwAAsIyYCT5z5szRkCFD1LFjR3Xq1CngmIqKCo0ePVpJSUlKT0/XbbfdpoaGhvAWCgAAola7SBfQXA0NDbryyis1ePBg/elPf/I7f+TIEV100UXq0qWLVq5cqb1792rcuHEyxuj3v/99BCoGAADRJmaCz+zZsyVJzzzzTMDzy5Yt00cffaRdu3YpJydHkvToo49q/PjxmjNnjlJSUsJVKgAAiFIx0+o6nlWrVqmwsNAdeiTpggsukMvl0rp164J+ncvlUm1trdcLAADEp7gJPlVVVcrMzPQ61rlzZyUkJKiqqiro1xUXF8vpdLpfubm5rV0qAACIkIgGn1mzZslmsx3ztXbt2mZ/ns1m8ztmjAl4vMnMmTNVU1Pjfu3ateuE5gIAAKJfRK/xmThxoq655ppjjunRo0ezPisrK0vvv/++17F9+/bp0KFDfitBnux2u+x2e7O+BwAAiG0RDT7p6elKT09vkc8aPHiw5syZo8rKSmVnZ0s6esGz3W5X//79W+R7AACA2BYzu7oqKir09ddfq6KiQkeOHNHGjRslSb169VJycrJGjhyp3r17a+zYsXrkkUf09ddfa/r06brpppvY0QUAACTFUPC577779Oyzz7rf9+vXT5L07rvvatiwYWrbtq2WLFmiCRMm6Ec/+pESExM1ZswY/eY3v4lUyQAAIMrETPB55plngt7Dp0n37t31xhtvhKcgAAAQc+JmOzsAAMDxEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBlEHwAAIBltIt0AdHGGCNJOlT/rQ59U6/6A/U6oAbVHamPcGUAACCYurqjf083/T0ejM0cb4TFfP755zrllFMiXQYAADgBu3btUrdu3YKeZ8XHR2pqqiSpoqJCTqczwtW0jtraWuXm5mrXrl1KSUmJdDmtgjnGByvMUbLGPJljfIjmORpjVFdXp5ycnGOOI/j4aNPm6GVPTqcz6v5QW1pKSgpzjAPMMX5YYZ7MMT5E6xybs2DBxc0AAMAyCD4AAMAyCD4+7Ha77r//ftnt9kiX0mqYY3xgjvHDCvNkjvEhHubIri4AAGAZrPgAAADLIPgAAADLIPgAAADLIPgAAADLIPh4ePLJJ5Wfn68OHTqof//+eu+99yJdUkDFxcU655xz5HA4lJGRoUsvvVSffvqp1xhjjGbNmqWcnBwlJiZq2LBh2rJli9cYl8ulSZMmKT09XUlJSbrkkkv0xRdfeI3Zt2+fxo4dK6fTKafTqbFjx2r//v2tPUU/xcXFstlsmjJlivtYvMzxyy+/1PXXX6+0tDR17NhRZ511ltatW+c+H+vzPHz4sO655x7l5+crMTFRPXv21AMPPKDGxsaYneOKFSs0evRo5eTkyGaz6bXXXvM6H875VFRUaPTo0UpKSlJ6erpuu+02NTQ0tOocDx06pDvuuEN9+vRRUlKScnJydMMNN2j37t1xM0dfN998s2w2mx577LG4m+PHH3+sSy65RE6nUw6HQ4MGDVJFRUXMzDFkBsYYYxYtWmTat29v/vCHP5iPPvrITJ482SQlJZmdO3dGujQ/F1xwgVm4cKH58MMPzcaNG81FF11kunfvbg4cOOAe89BDDxmHw2FeeeUVs3nzZnP11Veb7OxsU1tb6x5zyy23mK5du5qSkhKzfv16M3z4cNO3b19z+PBh95gLL7zQFBYWmrKyMlNWVmYKCwvNxRdfHNb5fvDBB6ZHjx7mzDPPNJMnT3Yfj4c5fv311yYvL8+MHz/evP/++6a8vNy8/fbbZtu2bXEzzwcffNCkpaWZN954w5SXl5uXXnrJJCcnm8ceeyxm5/jmm2+au+++27zyyitGknn11Ve9zodrPocPHzaFhYVm+PDhZv369aakpMTk5OSYiRMntuoc9+/fb37yk5+YF154wXzyySdm1apVZuDAgaZ///5enxHLc/T06quvmr59+5qcnBzz29/+Nq7muG3bNpOammpuv/12s379erN9+3bzxhtvmK+++ipm5hgqgs93fvjDH5pbbrnF69jpp59u7rzzzghV1HzV1dVGkiktLTXGGNPY2GiysrLMQw895B5TX19vnE6neeqpp4wxR39xtW/f3ixatMg95ssvvzRt2rQxS5cuNcYY89FHHxlJZvXq1e4xq1atMpLMJ598Eo6pmbq6OlNQUGBKSkpMUVGRO/jEyxzvuOMOM3To0KDn42GeF110kfnlL3/pdezyyy83119/vTEm9ufo+5dJOOfz5ptvmjZt2pgvv/zSPeZvf/ubsdvtpqamptXmGMgHH3xgJLn/sRgvc/ziiy9M165dzYcffmjy8vK8gk88zPHqq692/78YSKzNsTlodUlqaGjQunXrNHLkSK/jI0eOVFlZWYSqar6amhpJ3z9gtby8XFVVVV7zsdvtKioqcs9n3bp1OnTokNeYnJwcFRYWusesWrVKTqdTAwcOdI8ZNGiQnE5n2H4ut956qy666CL95Cc/8ToeL3N8/fXXNWDAAF155ZXKyMhQv3799Ic//MF9Ph7mOXToUP3P//yPPvvsM0nS//3f/2nlypX66U9/Gjdz9BTO+axatUqFhYVeD2W84IIL5HK5vNql4VBTUyObzaZOnTpJio85NjY2auzYsbr99tt1xhln+J2P9Tk2NjZqyZIlOvXUU3XBBRcoIyNDAwcO9GqHxfocAyH4SNqzZ4+OHDmizMxMr+OZmZmqqqqKUFXNY4zRtGnTNHToUBUWFkqSu+ZjzaeqqkoJCQnq3LnzMcdkZGT4fc+MjIyw/FwWLVqk9evXq7i42O9cvMzx888/14IFC1RQUKC33npLt9xyi2677TY999xz7vqaavYUS/O84447dO211+r0009X+/bt1a9fP02ZMkXXXnutu7ameo9VfzTP0VM451NVVeX3fTp37qyEhISwzrm+vl533nmnxowZ435wZTzMcd68eWrXrp1uu+22gOdjfY7V1dU6cOCAHnroIV144YVatmyZLrvsMl1++eUqLS111xbLcwyEp7N7sNlsXu+NMX7Hos3EiRO1adMmrVy50u/ciczHd0yg8eH4uezatUuTJ0/WsmXL1KFDh6DjYnmO0tF/cQ0YMEBz586VJPXr109btmzRggULdMMNNwStMZbm+cILL+gvf/mLnn/+eZ1xxhnauHGjpkyZopycHI0bNy5ofbE0x0DCNZ9Iz/nQoUO65ppr1NjYqCeffPK442NljuvWrdPjjz+u9evXh/x9YmWOTRsMfvazn2nq1KmSpLPOOktlZWV66qmnVFRUFPRrY2WOgbDiIyk9PV1t27b1S53V1dV+CTWaTJo0Sa+//rreffdddevWzX08KytLko45n6ysLDU0NGjfvn3HHPPVV1/5fd9//etfrf5zWbdunaqrq9W/f3+1a9dO7dq1U2lpqX73u9+pXbt27u8fy3OUpOzsbPXu3dvr2A9+8AP3jop4+LO8/fbbdeedd+qaa65Rnz59NHbsWE2dOtW9khcPc/QUzvlkZWX5fZ99+/bp0KFDYZnzoUOHdNVVV6m8vFwlJSXu1Z6m2mJ5ju+9956qq6vVvXt39++gnTt36t///d/Vo0cPd22xPMf09HS1a9fuuL+DYnmOgRB8JCUkJKh///4qKSnxOl5SUqIhQ4ZEqKrgjDGaOHGiFi9erHfeeUf5+fle5/Pz85WVleU1n4aGBpWWlrrn079/f7Vv395rTGVlpT788EP3mMGDB6umpkYffPCBe8z777+vmpqaVv+5/PjHP9bmzZu1ceNG92vAgAG67rrrtHHjRvXs2TPm5yhJP/rRj/xuRfDZZ58pLy9PUnz8WX7zzTdq08b7V03btm3d/9qMhzl6Cud8Bg8erA8//FCVlZXuMcuWLZPdblf//v1bdZ5NoWfr1q16++23lZaW5nU+1uc4duxYbdq0yet3UE5Ojm6//Xa99dZbcTHHhIQEnXPOOcf8HRTrcwwoPNdQR7+m7ex/+tOfzEcffWSmTJlikpKSzI4dOyJdmp9f//rXxul0muXLl5vKykr365tvvnGPeeihh4zT6TSLFy82mzdvNtdee23A7bTdunUzb7/9tlm/fr05//zzA25RPPPMM82qVavMqlWrTJ8+fcK+nb2J564uY+Jjjh988IFp166dmTNnjtm6dav561//ajp27Gj+8pe/xM08x40bZ7p27erezr548WKTnp5uZsyYEbNzrKurMxs2bDAbNmwwksz8+fPNhg0b3DuawjWfpi3CP/7xj8369evN22+/bbp169YiW4SPNcdDhw6ZSy65xHTr1s1s3LjR6/eQy+WKizkG4rurKx7muHjxYtO+fXvz9NNPm61bt5rf//73pm3btua9996LmTmGiuDj4T//8z9NXl6eSUhIMGeffbZ7e3i0kRTwtXDhQveYxsZGc//995usrCxjt9vNeeedZzZv3uz1Od9++62ZOHGiSU1NNYmJiebiiy82FRUVXmP27t1rrrvuOuNwOIzD4TDXXXed2bdvXxhm6c83+MTLHP/xj3+YwsJCY7fbzemnn26efvppr/OxPs/a2lozefJk0717d9OhQwfTs2dPc/fdd3v9BRlrc3z33XcD/j84bty4sM9n586d5qKLLjKJiYkmNTXVTJw40dTX17fqHMvLy4P+Hnr33XfjYo6BBAo+8TDHP/3pT6ZXr16mQ4cOpm/fvua1116LqTmGymaMMa27pgQAABAduMYHAABYBsEHAABYBsEHAABYBsEHAABYBsEHAABYBsEHAABYBsEHAABYBsEHAABYBsEHQMQYY/SrX/1Kqampstls2rhxY6RLAhDnCD4AImbp0qV65pln9MYbb6iyslKFhYUn/Znjx4/XpZdeevLFNVN9fb3Gjx+vPn36qF27dmH93gBC1y7SBQCwru3btys7OzusT09vriNHjshms/k9WT7QuMTERN1222165ZVXwlQdgBPFig+AiBg/frwmTZqkiooK2Ww29ejRQ8YYPfzww+rZs6cSExPVt29fvfzyy+6vOXLkiG688Ubl5+crMTFRp512mh5//HH3+VmzZunZZ5/V3//+d9lsNtlsNi1fvlzLly+XzWbT/v373WM3btwom82mHTt2SJKeeeYZderUSW+88YZ69+4tu92unTt3qqGhQTNmzFDXrl2VlJSkgQMHavny5e7PSUpK0oIFC3TTTTcpKyurtX9sAE4SKz4AIuLxxx/XKaecoqefflpr1qxR27Ztdc8992jx4sVasGCBCgoKtGLFCl1//fXq0qWLioqK1NjYqG7duunFF19Uenq6ysrK9Ktf/UrZ2dm66qqrNH36dH388ceqra3VwoULJUmpqakqKytrVk3ffPONiouL9cc//lFpaWnKyMjQL37xC+3YsUOLFi1STk6OXn31VV144YXavHmzCgoKWvNHBKAVEHwARITT6ZTD4VDbtm2VlZWlgwcPav78+XrnnXc0ePBgSVLPnj21cuVK/dd//ZeKiorUvn17zZ492/0Z+fn5Kisr04svvqirrrpKycnJSkxMlMvlOqHVl0OHDunJJ59U3759JR1txf3tb3/TF198oZycHEnS9OnTtXTpUi1cuFBz585tgZ8EgHAi+ACICh999JHq6+s1YsQIr+MNDQ3q16+f+/1TTz2lP/7xj9q5c6e+/fZbNTQ06KyzzmqRGhISEnTmmWe6369fv17GGJ166qle41wul9LS0lrkewIIL4IPgKjQ2NgoSVqyZIm6du3qdc5ut0uSXnzxRU2dOlWPPvqoBg8eLIfDoUceeUTvv//+MT+76QJlY4z72KFDh/zGJSYmymazedXUtm1brVu3Tm3btvUam5ycHMLsAEQLgg+AqNB0QXFFRYWKiooCjnnvvfc0ZMgQTZgwwX1s+/btXmMSEhJ05MgRr2NdunSRJFVWVqpz586S1Kx7BvXr109HjhxRdXW1zj333FCmAyBKEXwARAWHw6Hp06dr6tSpamxs1NChQ1VbW6uysjIlJydr3Lhx6tWrl5577jm99dZbys/P15///GetWbNG+fn57s/p0aOH3nrrLX366adKS0uT0+lUr169lJubq1mzZunBBx/U1q1b9eijjx63plNPPVXXXXedbrjhBj366KPq16+f9uzZo3feeUd9+vTRT3/6U0lH23QNDQ36+uuvVVdX5w5VLdWCA9CCDABEyG9/+1uTl5fnft/Y2Ggef/xxc9ppp5n27dubLl26mAsuuMCUlpYaY4ypr68348ePN06n03Tq1Mn8+te/Nnfeeafp27ev+zOqq6vNiBEjTHJyspFk3n33XWOMMStXrjR9+vQxHTp0MOeee6556aWXjCRTXl5ujDFm4cKFxul0+tXY0NBg7rvvPtOjRw/Tvn17k5WVZS677DKzadMm95i8vDwjye8FIPrYjPFoegMAAMQxbmAIAAAsg+ADAAAsg+ADAAAsg+ADAAAsg+ADAAAsg+ADAAAsg+ADAAAsg+ADAAAsg+ADAAAsg+ADAAAsg+ADAAAs4/8B1b1Al+y5Ix8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_train)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.singular_values_)\n",
    "X_new = pca.transform(X_train)\n",
    "\n",
    "clf221 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=100, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='newton-cg', max_iter=100, multi_class='multinomial', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None).fit(X_new, y_train)\n",
    "disp = DecisionBoundaryDisplay.from_estimator(clf221, X_new, xlabel = \"feature1\", ylabel =\"feature2\", response_method=\"predict\", alpha=0.5)\n",
    "disp.title(\"Decision Boundary after application of PCA\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a09b50",
   "metadata": {},
   "source": [
    "### Part 2: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2aef35",
   "metadata": {},
   "source": [
    "We will repeat the process for random forests; however, rather than manually trying all of the possible combinations of hyperparameters, we will implement a grid search, in which we write code that will have the computer go through all the possibilities and return the best results. \n",
    "\n",
    "From outside reading, we know that the two most important hyperparameters for random forests are the number of random features to sample at each split point (max_features) and number of decision trees (n_estimators). So, we will try the options 10, 100, and 500 for n_estimators and 1-6, as well as sqrt and log2, for max_features. 'sqrt'refers to setting the # of features to sqrt(n_features), where n_features is the total number of features being used (6 in our case). 'log2' refers to setting the # of features to log2\\*n_features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5afba827",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m cv \u001b[38;5;241m=\u001b[39m RepeatedStratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_repeats\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mgrid, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, cv\u001b[38;5;241m=\u001b[39mcv, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,error_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# summarize results\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest: \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m using \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (grid_result\u001b[38;5;241m.\u001b[39mbest_score_, grid_result\u001b[38;5;241m.\u001b[39mbest_params_))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1061\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 938\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#grid searching key parameters for RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "# define dataset\n",
    "X, y = X_test, y_test\n",
    "# define models and parameters\n",
    "model = RandomForestClassifier()\n",
    "n_estimators = [10, 100, 500]\n",
    "max_features = [1, 2, 3, 'sqrt', 'log2']\n",
    "# define grid search\n",
    "grid = dict(n_estimators=n_estimators,max_features=max_features)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784d9d96",
   "metadata": {},
   "source": [
    "After scanning the space defined above (8 possible values of max_features and 3 possible values of n_estimators, so 24 possibilities), this code has found that the optimal number of random features to sample at each node is 3, and that the optimal number of trees in the forest is 1000. (At least, those are the best values of the options we inputted). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a67aa4",
   "metadata": {},
   "source": [
    "Next, let us calculate the F1 scores for all options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655fab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variations of 10-tree forests\n",
    "clfrf7=RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf7 = clfrf7.predict(X_test)\n",
    "f1rf7=sklearn.metrics.f1_score(y_test, y_predrf7, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf7)\n",
    "\n",
    "clfrf8=RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf8 = clfrf8.predict(X_test)\n",
    "f1rf8=sklearn.metrics.f1_score(y_test, y_predrf8, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf8)\n",
    "\n",
    "clfrf9=RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=3, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf9 = clfrf9.predict(X_test)\n",
    "f1rf9=sklearn.metrics.f1_score(y_test, y_predrf9, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf9)\n",
    "\n",
    "clfrf10=RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=4, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf10 = clfrf10.predict(X_test)\n",
    "f1rf10=sklearn.metrics.f1_score(y_test, y_predrf10, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf10)\n",
    "\n",
    "clfrf11=RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=5, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf11 = clfrf11.predict(X_test)\n",
    "f1rf11=sklearn.metrics.f1_score(y_test, y_predrf11, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf11)\n",
    "\n",
    "clfrf12=RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=6, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf12 = clfrf12.predict(X_test)\n",
    "f1rf12=sklearn.metrics.f1_score(y_test, y_predrf12, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf12)\n",
    "\n",
    "clfrf12s=RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf12s = clfrf12s.predict(X_test)\n",
    "f1rf12s=sklearn.metrics.f1_score(y_test, y_predrf12s, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf12s)\n",
    "\n",
    "clfrf12l=RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='log2', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf12l = clfrf12l.predict(X_test)\n",
    "f1rf12l=sklearn.metrics.f1_score(y_test, y_predrf12l, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf12l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45df3c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variations of 100-tree forests\n",
    "clfrf1=RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf1 = clfrf1.predict(X_test)\n",
    "f1rf1=sklearn.metrics.f1_score(y_test, y_predrf1, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf1)\n",
    "\n",
    "clfrf2=RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf2 = clfrf2.predict(X_test)\n",
    "f1rf2=sklearn.metrics.f1_score(y_test, y_predrf2, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf2)\n",
    "\n",
    "clfrf3=RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=3, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf3 = clfrf3.predict(X_test)\n",
    "f1rf3=sklearn.metrics.f1_score(y_test, y_predrf3, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf3)\n",
    "\n",
    "clfrf4=RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=4, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf4 = clfrf4.predict(X_test)\n",
    "f1rf4=sklearn.metrics.f1_score(y_test, y_predrf4, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf4)\n",
    "\n",
    "clfrf5=RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=5, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf5 = clfrf5.predict(X_test)\n",
    "f1rf5=sklearn.metrics.f1_score(y_test, y_predrf5, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf5)\n",
    "\n",
    "clfrf6=RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=6, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf6 = clfrf6.predict(X_test)\n",
    "f1rf6=sklearn.metrics.f1_score(y_test, y_predrf6, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf6)\n",
    "\n",
    "clfrf6l=RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=\"sqrt\", max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf6l = clfrf6l.predict(X_test)\n",
    "f1rf6l=sklearn.metrics.f1_score(y_test, y_predrf6l, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf6l)\n",
    "\n",
    "clfrf6s=RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=\"log2\", max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf6s = clfrf6s.predict(X_test)\n",
    "f1rf6s=sklearn.metrics.f1_score(y_test, y_predrf6s, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf6s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03bea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variations of 500-tree forests\n",
    "clfrf13=RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf13 = clfrf13.predict(X_test)\n",
    "f1rf13=sklearn.metrics.f1_score(y_test, y_predrf13, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf13)\n",
    "\n",
    "clfrf14=RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=2, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf14 = clfrf14.predict(X_test)\n",
    "f1rf14=sklearn.metrics.f1_score(y_test, y_predrf14, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf14)\n",
    "\n",
    "clfrf15=RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=3, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf15 = clfrf15.predict(X_test)\n",
    "f1rf15=sklearn.metrics.f1_score(y_test, y_predrf15, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf15)\n",
    "\n",
    "clfrf16=RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=4, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf16 = clfrf16.predict(X_test)\n",
    "f1rf16=sklearn.metrics.f1_score(y_test, y_predrf16, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf16)\n",
    "\n",
    "clfrf17=RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=5, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf17 = clfrf17.predict(X_test)\n",
    "f1rf17=sklearn.metrics.f1_score(y_test, y_predrf17, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf17)\n",
    "\n",
    "clfrf18=RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=6, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf18 = clfrf18.predict(X_test)\n",
    "f1rf18=sklearn.metrics.f1_score(y_test, y_predrf18, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf18)\n",
    "\n",
    "clfrf18s=RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf18s = clfrf18s.predict(X_test)\n",
    "f1rf18s=sklearn.metrics.f1_score(y_test, y_predrf18s, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf18s)\n",
    "\n",
    "clfrf18l=RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='log2', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
    "y_predrf18l = clfrf18l.predict(X_test)\n",
    "f1rf18l=sklearn.metrics.f1_score(y_test, y_predrf18l, labels=None, pos_label=1, average='macro', sample_weight=None, zero_division='warn')\n",
    "print(f1rf18l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719c8567",
   "metadata": {},
   "source": [
    "### Part 3: Neural Net"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
